{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/rivacon_frontmark_combined_header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Data Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pyvacon.analytics as analytics\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import pyvacon.tools.converter as converter\n",
    "import pyvacon.tools.enums as enums\n",
    "import math\n",
    "from numpy import arange\n",
    "from numpy import meshgrid\n",
    "import numpy as np\n",
    "from ipywidgets import interact #, interactive, fixed, interact_manual, Layout\n",
    "#import ipywidgets as widgets\n",
    "\n",
    "import pyvacon.instruments.testdata as ins_testdata\n",
    "import pyvacon.marketdata.plot as mkt_plot #import module for plotting functionality\n",
    "import pyvacon.pricing.tools as pricing_tools\n",
    "#the next lin is a jupyter internal command to show the matplotlib graphs within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "refdate = analytics.ptime(2017,1,1,0,0,0) #dates which enters analytics objects must be analytics ptimes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup market data and instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# create sample data\n",
    "#create sample dividend table\n",
    "\n",
    "# dividend table neede fo forward curve\n",
    "object_id = \"TEST_DIV\" \n",
    "ex_dates = converter.createPTimeList(refdate, [dt.datetime(2018,3,29), dt.datetime(2019,3,29), dt.datetime(2020,3,29), dt.datetime(2021,3,29)])\n",
    "pay_dates = converter.createPTimeList(refdate, [dt.datetime(2018,4,1), dt.datetime(2019,4,1), dt.datetime(2020,4,1), dt.datetime(2021,4,1)])\n",
    "tax_factors = analytics.vectorDouble([1.0, 1.0, 1.0, 1.0])\n",
    "div_yield = analytics.vectorDouble([0, 0.005, 0.01, 0.01])\n",
    "div_cash = analytics.vectorDouble([3.0, 2.0, 1.0, 0.0])\n",
    "div_table=analytics.DividendTable(object_id, refdate, ex_dates, div_yield, div_cash, tax_factors, pay_dates)\n",
    "spot = 100.0\n",
    "\n",
    "# discount and borrow neede for forward curve\n",
    "dates = converter.createPTimeList(refdate,[0, 365, 2*365, 3*365, 5*365])\n",
    "df = analytics.vectorDouble([1.0,math.exp(-1.0*0.02), math.exp(-2.0*0.03), math.exp(-3.0*0.035), math.exp(-5.0*0.04)])\n",
    "dc = analytics.DiscountCurve('TEST_DC', refdate, dates, df, enums.DayCounter.ACT365_FIXED, \n",
    "                             enums.InterpolationType.HAGAN_DF, enums.ExtrapolationType.NONE)\n",
    "\n",
    "df_bc = analytics.vectorDouble([1.0, math.exp(-1.0*0.05), math.exp(-2.0*0.05), math.exp(-3.0*0.05), math.exp(-5.0*0.05)])\n",
    "bc = analytics.DiscountCurve('TEST_BC', refdate, dates, df_bc, enums.DayCounter.ACT365_FIXED, \n",
    "                             enums.InterpolationType.HAGAN_DF, enums.ExtrapolationType.NONE)\n",
    "#forward curve\n",
    "forward_curve = analytics.EquityForwardCurve('orig', refdate, spot, dc, bc, div_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility\n",
    "#### SSVI\n",
    "This parametrization is inspired by the volatility structure provided by stochastic volatility models. The total variance $w(k,t)$ for a strike log strike $k$ and time-to-maturity $t$ is given by\n",
    "$$ w(k,t) = \\frac{\\theta_t}{2}\\left( 1+\\rho\\phi(\\theta_t)k+\\sqrt{(\\phi(\\theta_t)k+\\rho)^2+(1-\\rho^2)}  \\right) $$ \n",
    "and \n",
    "$$ \\phi(\\theta_t) = \\frac{\\eta}{\\theta_t^\\gamma(1+\\theta_t)^{1-\\gamma}} $$\n",
    "for parameters $\\rho$, $\\eta$, $\\gamma$ and given atm implied total variances $\\theta_t:=\\sigma^2(t)t$. The term structure of implied total variances is internally approximated by interpolation from given atm volatilities. The nice property of this surface is that there are very simple conditions on the parameters to guarantee that the surface is free of arbitrage, see [gatheral_jacquier_svi](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2033323)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "expiries = [1.0/12.0, 0.75, 1.0, 2.0]\n",
    "atm_vols =  [0.3, 0.28, 0.25, 0.24]\n",
    "gamma = 0.5\n",
    "rho = -0.7\n",
    "eta = 1.0\n",
    "ssvi_param = analytics.VolatilityParametrizationSSVI(expiries, atm_vols, rho, eta, gamma)\n",
    "obj_id = 'TEST_SURFACE'\n",
    "vol_surf = analytics.VolatilitySurface(obj_id, refdate, forward_curve, enums.DayCounter.ACT365_FIXED, ssvi_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down and Out Put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#setup test instrument\n",
    "rel_expiry = 365 # expiry in number of days\n",
    "rel_level = 0.8 #barrier level relative to spot\n",
    "rel_rebate = 0 # rebate relative to spot\n",
    "rel_strike = 1.0 # strike relative to spot\n",
    "dop = ins_testdata.DOP.__create_DOP__(spot, 'EUR', rel_expiry, rel_level, rel_strike, rel_rebate, 'TEST_UDL', refdate)\n",
    "\n",
    "# setup pricing data\n",
    "dop_pricing_data = analytics.LocalVolPdePricingData()\n",
    "dop_pricing_data.pricer = 'LocalVolPdePricer'\n",
    "dop_pricing_data.valDate = refdate\n",
    "dop_pricing_data.pricingRequest = analytics.PricingRequest()\n",
    "#dop_pricing_data.pricingRequest.s\n",
    "dop_pricing_data.vol = vol_surf\n",
    "dop_pricing_data.spec = dop\n",
    "dop_pricing_data.param = analytics.PdePricingParameter()\n",
    "dop_pricing_data.dsc = dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Data Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividend Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# create scenario, set bucket and apply\n",
    "#help(analytics.DividendScenario)\n",
    "div_scenario = analytics.DividendScenario('DIV_SCEN', refDate = refdate, relativeDates=False, udls=[])\n",
    "bucket_from = converter.getLTime(-50, ex_dates[1])\n",
    "bucket_to = converter.getLTime(50, ex_dates[1])\n",
    "#help(analytics.DividendScenario.setBucket)\n",
    "div_scenario.setBucket(bucketFrom = bucket_from, bucketTo = bucket_to, relativeDates = False, \n",
    "                                     cashShiftAbs= 1.0, cashShiftRel = 1.10, yieldShiftAbs = 0, yieldShiftRel = 1.0, \n",
    "                                     taxShiftAbs = 0.0, taxShiftRel = 1.0)\n",
    "#help(div_scenario.apply)\n",
    "div_table_shifted = div_scenario.apply(div_table, refdate)\n",
    "#help(analytics.EquityForwardCurve)\n",
    "forward_curve_div_shifted = analytics.EquityForwardCurve('shifted div', refdate, spot, dc, bc, div_table_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#plot the two forward curves\n",
    "mkt_plot.curve(forward_curve, range(0,3*365), refdate)\n",
    "mkt_plot.curve(forward_curve_div_shifted, range(0,3*365), refdate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discount curve scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup discoun curve scenario\n",
    "bucket_from = converter.getLTime(-180, dates[1])\n",
    "bucket_to = converter.getLTime(180, dates[1])\n",
    "#hat scenario\n",
    "dc_hat_scenario = analytics.DiscountCurveScenario('HAT_SCEN', refdate, False)\n",
    "dc_hat_scenario.setHatBucketShift(fromBucket = bucket_from, midBucket = dates[1], toBucket = bucket_to, absShift = 0.005, relShift = 0.0)\n",
    "dc_hat_shifted = dc_hat_scenario.apply(dc, refdate)\n",
    "#constant scenario\n",
    "dc_const_scenario = analytics.DiscountCurveScenario('CONST_SCEN', refdate, False)\n",
    "dc_const_scenario.setConstantBucketShift(fromBucket = bucket_from, toBucket = bucket_to, absShift = 0.00, relShift = 0.1)\n",
    "dc_const_shifted = dc_const_scenario.apply(dc, refdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_plot.curve(dc,range(0,3*365), refdate, True )\n",
    "mkt_plot.curve(dc_hat_shifted,range(0,3*365), refdate, True)\n",
    "mkt_plot.curve(dc_const_shifted,range(0,3*365), refdate, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility scenarios\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket shifted volatility surface\n",
    "The VolatilitySurfaceBucketShifted is the basis for the computation of vega buckets. This class provides th functionality to apply a bucket shift (bump of the volatility surface at a certain point). Up to now, two different bum-parametrizations are implemented:\n",
    "- Radial basis function (RBF) with global support: For given strike-points $x_i$ and ttm $t_j$ one has the parametrization of the (i,j)-th bump by\n",
    "$$b_{i,j}(x,t)=\\frac{e^{(-s_x \\cdot(x-x_i)^2 - s_t \\cdot(t-t_j)^2)}}{\\sum_i b_{i,j}(x,t)}$$ \n",
    "where the denominator ensures that we have a partition of unity \n",
    "- Transformed radial basis functions with local support: For given strike-points $x_i$ and ttm $t_j$ one has the parametrization of the i-th bump by:\n",
    "$$b_{i,j}(x,t)=\\frac{e^{-s_x / ( 1.0- ( 2.0(x-x_i)/(x_{i+1}-x_{i-1}) )^2 )}}{\\sum_i b_{i,j}(x,t)}$$ \n",
    "for $x\\in [x_{i-1},x_{i+1}]$ and $0$ otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     13,
     15
    ]
   },
   "outputs": [],
   "source": [
    "#setup buckets and plot them\n",
    "bucket_i = 1\n",
    "bucket_j = 0\n",
    "bucket_scale_x = 1000.0 #1000 #1.000 #\n",
    "bucket_scale_t = 500.0 #500 #1.0000 #\n",
    "shift = 0.001\n",
    "\n",
    "bucket_strikes = arange(0.7, 1.4, 0.1) #[0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "bucket_expiries_integer = [30, 60, 180, 365, 365+180]\n",
    "bucket_expiries = [x/365.0 for x in bucket_expiries_integer] #arange(30.0/365.0, 1.1, 30.0/365.0) \n",
    "#ttm = bucket_expiries_integer[bucket_j] # time to maturity in days\n",
    "days_to_expiry = [bucket_expiries_integer[bucket_j-1], bucket_expiries_integer[bucket_j], bucket_expiries_integer[bucket_j+1]]\n",
    "\n",
    "vol_bucket_surface = analytics.VolatilitySurfaceBucketShifted(vol_surf, bucket_strikes, bucket_expiries, shift)\n",
    "    \n",
    "def plot_surfaces(bucket_type):\n",
    "    #create sample vol, apply bucket shift and plot\n",
    "    \n",
    "    # comment/uncomment to use the different bucket parametrizations\n",
    "    if bucket_type == 'RBF':\n",
    "        vol_bucket_surface.setRBF(bucket_scale_x, bucket_scale_t)\n",
    "    else:\n",
    "        vol_bucket_surface.setSimpleExponentialLocalSupport(bucket_scale_x, bucket_scale_t)\n",
    "    vol_bucket_surface.setBucket(bucket_i, bucket_j)\n",
    "\n",
    "    expiry = converter.getLTime(days_to_expiry[1], refdate)\n",
    "    xstrikes = arange(0.4,1.8, 0.005)\n",
    "    # plot vols at bucket expiry\n",
    "    #\n",
    "    #\n",
    "    orix_x, orig_y = rcParams['figure.figsize'] \n",
    "    rcParams['figure.figsize'] = 18,10\n",
    "    plt.subplot(2,3,1)\n",
    "\n",
    "    mkt_plot.vol(vol_surf, days_to_expiry, xstrikes, refdate)\n",
    "    plt.title('unshifted')\n",
    "    plt.subplot(2,3,2)\n",
    "    mkt_plot.vol(vol_bucket_surface, days_to_expiry, xstrikes, refdate)\n",
    "    plt.title('bucket shifted')\n",
    "    \n",
    "    # calc difference\n",
    "    \n",
    "    diff = []\n",
    "    for x in xstrikes:\n",
    "        diff.append(vol_bucket_surface.calcImpliedVol(refdate, expiry, x)-vol_surf.calcImpliedVol(refdate, expiry, x))\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.plot(xstrikes, diff, '-x')\n",
    "    plt.title('diff')\n",
    "    \n",
    "    #plot color surf\n",
    "    expiries = [x for x in range(30, 15*30, 10)]\n",
    "    strikes =  arange(0.7, 1.4, 0.005)\n",
    "    #plt.figure()\n",
    "    #plt.pcolor(x,y,vega_bucket)\n",
    "    plt.subplot(2,3,4)\n",
    "    X,Y,vol_surf_un = mkt_plot.vol_surface(vol_surf, expiries, strikes, refdate )\n",
    "    plt.subplot(2,3,5)\n",
    "    X,Y,vol_surf_bucket = mkt_plot.vol_surface(vol_bucket_surface, expiries, strikes, refdate )\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.pcolor(X,Y,vol_surf_bucket-vol_surf_un)\n",
    "    plt.xlabel('x-strikes')\n",
    "    plt.xlabel('ttm')\n",
    "    rcParams['figure.figsize']  = orix_x, orig_y\n",
    "\n",
    "interact(plot_surfaces, bucket_type = ['RBF', 'SIMPLE_EXP_LOCAL'])\n",
    "#plt.pcolor(X,Y,vol_surf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#check for arbitrage\n",
    "arbStrikes = analytics.vectorDouble()\n",
    "arbExpiries = analytics.vectorDouble()\n",
    "arbType = analytics.vectorString()\n",
    "expiries = converter.createPTimeList(refdate, range(10,365, 5))\n",
    "analytics.VolatilityCalibrator.checkArbitrage(arbStrikes, arbExpiries, arbType, vol_bucket_surface, 0.4, 1.6, 0.001, expiries, refdate, 0.000001)\n",
    "mkt_plot.arbitrage_points(arbStrikes,arbExpiries,arbType, 0.4, 1.6, 3.0)\n",
    "#vol =vol_surf.calcImpliedVol(refdate,converter.getLTime(refdate, 180), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vega Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = {'RBF': (500.0, 250.0),\n",
    "          'LOCAL_RBF': (10.0, 5.0)}\n",
    "parametrization = 'RBF' #'RBF' # 'LOCAL_RBF'\n",
    "vega_bucket = pricing_tools.create_vega_bucket(dop_pricing_data,bucket_strikes, bucket_expiries, shift, \n",
    "                                               scale_x=setting[parametrization][0], scale_t=setting[parametrization][1], \n",
    "                                               bucket_type =parametrization )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = meshgrid(bucket_strikes, bucket_expiries)\n",
    "rcParams['figure.figsize'] = 6,4\n",
    "plt.pcolor(x,y,vega_bucket)\n",
    "plt.colorbar()\n",
    "plt.xlabel('strike')\n",
    "plt.xticks(bucket_strikes)\n",
    "plt.ylabel('ttm')\n",
    "#print(vega_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dop_pricing_data.pricingRequest.setVega(True)\n",
    "vega_scale = 0.01\n",
    "dop_pricing_data.pricingRequest.setVegaScale(vega_scale)\n",
    "vegas = analytics.price(dop_pricing_data).getVegas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vega_from_buckets = vega_scale * np.sum(vega_bucket)\n",
    "vega = vegas['TEST_SURFACE']\n",
    "print('vega: ' + str(vega) + ', sum of buckets: ' + str(vega_from_buckets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket_surface(bucket_type, bucket_scale_x, bucket_scale_t, shift):\n",
    "    vol_bucket_surface = analytics.VolatilitySurfaceBucketShifted(vol_surf, bucket_strikes, bucket_expiries, shift)\n",
    "    # coment/uncomment to use the different bucket parametrizations\n",
    "    if bucket_type == 'RBF':\n",
    "        vol_bucket_surface.setRBF(bucket_scale_x, bucket_scale_t)\n",
    "    else:\n",
    "        vol_bucket_surface.setSimpleExponentialLocalSupport(bucket_scale_x, bucket_scale_t)\n",
    "        \n",
    "t = 'RBF'\n",
    "result = []\n",
    "if True:\n",
    "    for bucket_scale_x in [1, 10]: # , 1000, 2000]:\n",
    "        for bucket_scale_t in [1, 10]: #, 1000, 2000]:\n",
    "            for shift in [0.005, 0.002, 0.001, 0.0005]:\n",
    "                vega_bucket = pricing_tools.create_vega_bucket(dop_pricing_data,bucket_strikes, bucket_expiries, shift, scale_x=bucket_scale_x, scale_t=bucket_scale_t, bucket_type = t)\n",
    "                vega_from_buckets = vega_scale * np.sum(vega_bucket)\n",
    "                result.append( {'type': t, 'bucket_scale_x': bucket_scale_x, 'bucket_scale_t' : bucket_scale_t, 'shift': shift, 'vega_bucket': vega_from_buckets, 'vega': vega, 'abs(diff)': abs(vega_from_buckets - vega)} )\n",
    "            \n",
    "\n",
    "t = 'LOCAL_RBF'\n",
    "for bucket_scale_x in [100, 1000]: # , 1000, 2000]:\n",
    "    for bucket_scale_t in [100, 1000]: #, 1000, 2000]:\n",
    "        for shift in [0.005, 0.002]: #, 0.001, 0.0005]:\n",
    "            vega_bucket = pricing_tools.create_vega_bucket(dop_pricing_data,bucket_strikes, bucket_expiries, shift, scale_x=bucket_scale_x, scale_t=bucket_scale_t, bucket_type = t)\n",
    "            vega_from_buckets = vega_scale * np.sum(vega_bucket)\n",
    "            result.append( {'type': t, 'bucket_scale_x': bucket_scale_x, 'bucket_scale_t' : bucket_scale_t, 'shift': shift, 'vega_bucket': vega_from_buckets, 'vega': vega, 'abs(diff)': abs(vega_from_buckets - vega)} )\n",
    "pd.DataFrame(result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vega hedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analytics.setLogLevel('DEBUG')\n",
    "bucket_scale_x = 500.0 #1.0 #1000\n",
    "bucket_scale_t = 250.0 #1.0 #500\n",
    "bucket_type = 'RBF' #'LOCAL_RBF' #'RBF'\n",
    "vega_hedge = pricing_tools.compute_vega_hedge(dop_pricing_data,bucket_strikes, bucket_expiries, shift, scale_x=bucket_scale_x, \n",
    "                                              scale_t=bucket_scale_t, bucket_type = bucket_type,  optimMethod='Powell', \n",
    "                       optimOptions = {'xtol': 1e-5, 'ftol': 1e-6, 'maxiter': 100, 'maxfev': 20000, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(vega_hedge)\n",
    "#plt.style.use('default')\n",
    "x, y = meshgrid(bucket_strikes, bucket_expiries)\n",
    "rcParams['figure.figsize'] = 6,4\n",
    "plt.pcolor(x,y, vega_hedge)\n",
    "plt.colorbar()\n",
    "plt.xlabel('strike')\n",
    "plt.xticks(bucket_strikes)\n",
    "plt.ylabel('ttm')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General hedging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def setup_ssvi_vol_scenarios(base_vol):\n",
    "    scenarios = []\n",
    "    ssvi = analytics.VolatilityParametrizationSSVI.fromVolParametrization(base_vol.getVolParametrization())\n",
    "    expiries = ssvi.getExpiryTimes()\n",
    "    atm_vols =  ssvi.getAtmfVols()\n",
    "    gamma = ssvi.getGamma()\n",
    "    rho = ssvi.getRho()    \n",
    "    eta = ssvi.getEta()\n",
    "    refdate = analytics.ptime()\n",
    "    base_vol.getRefDate(refdate)\n",
    "    ssvi_param = analytics.VolatilityParametrizationSSVI(expiries, atm_vols, rho, 1.1 * eta, gamma)\n",
    "    vol_surf_eta_up = analytics.VolatilitySurface('ETA_UP', refdate, base_vol.getForwardCurve(), \n",
    "                                           enums.DayCounter.ACT365_FIXED, ssvi_param)\n",
    "    scenarios.append(vol_surf_eta_up)\n",
    "    \n",
    "    ssvi_param = analytics.VolatilityParametrizationSSVI(expiries, atm_vols, 1.1*rho, eta, gamma)\n",
    "    vol_surf_rho_up = analytics.VolatilitySurface('ETA_UP', refdate, base_vol.getForwardCurve(), \n",
    "                                           enums.DayCounter.ACT365_FIXED, ssvi_param)\n",
    "    scenarios.append(vol_surf_rho_up)\n",
    "    \n",
    "    ssvi_param = analytics.VolatilityParametrizationSSVI(expiries, atm_vols, rho, 1.1*eta, gamma)\n",
    "    vol_surf_eta_up = analytics.VolatilitySurface('ETA_UP', refdate, base_vol.getForwardCurve(), \n",
    "                                           enums.DayCounter.ACT365_FIXED, ssvi_param)\n",
    "    scenarios.append(vol_surf_eta_up)\n",
    "    \n",
    "    ssvi_param = analytics.VolatilityParametrizationSSVI(expiries, atm_vols, rho, eta, 1.1* gamma)\n",
    "    vol_surf_gamma_up = analytics.VolatilitySurface('ETA_UP', refdate, base_vol.getForwardCurve(), \n",
    "                                           enums.DayCounter.ACT365_FIXED, ssvi_param)\n",
    "    scenarios.append(vol_surf_gamma_up)\n",
    "    \n",
    "    \n",
    "    base_vol.getRefDate(refdate)\n",
    "    for i in range(len(atm_vols)):\n",
    "        shifted_atm_vol = analytics.vectorDouble([x for x in atm_vols])\n",
    "        shifted_atm_vol[i] += 0.005\n",
    "        ssvi_param = analytics.VolatilityParametrizationSSVI(expiries, shifted_atm_vol, rho, eta, gamma)\n",
    "        vol_surf_atm = analytics.VolatilitySurface('ETA_UP', refdate, base_vol.getForwardCurve(), \n",
    "                                               enums.DayCounter.ACT365_FIXED, ssvi_param)\n",
    "        scenarios.append(vol_surf_atm)\n",
    "    return scenarios\n",
    "    \n",
    "    \n",
    "hedge_ins = [{'PAYOFF': 'P', 'STRIKE': 70.0, 'EXPIRY': analytics.ptime(2017,6,1,0,0,0)},\n",
    "             {'PAYOFF': 'P', 'STRIKE': 75.0, 'EXPIRY': analytics.ptime(2017,6,1,0,0,0)},\n",
    "            {'PAYOFF': 'C', 'STRIKE': 100.0, 'EXPIRY': analytics.ptime(2017,6,1,0,0,0)},\n",
    "            {'PAYOFF': 'C', 'STRIKE': 110.0, 'EXPIRY': analytics.ptime(2017,6,1,0,0,0)},\n",
    "            {'PAYOFF': 'P', 'STRIKE': 70.0, 'EXPIRY': analytics.ptime(2018,1,1,0,0,0)},\n",
    "            {'PAYOFF': 'P', 'STRIKE': 75.0, 'EXPIRY': analytics.ptime(2018,1,1,0,0,0)},\n",
    "            {'PAYOFF': 'C', 'STRIKE': 100.0, 'EXPIRY': analytics.ptime(2018,1,1,0,0,0)},\n",
    "            {'PAYOFF': 'C', 'STRIKE': 110.0, 'EXPIRY': analytics.ptime(2018,1,1,0,0,0)}]    \n",
    "\n",
    "scenarios = setup_ssvi_vol_scenarios(vol_surf)\n",
    "scenario_weights = [1.0 for x in scenarios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_tools.compute_hedge(dop_pricing_data, scenarios, scenario_weights, hedge_ins,  optimOptions = {'xtol': 1e-3, 'ftol': 1e-3, 'maxiter': 20, 'maxfev': 1000, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "175px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
