{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/rivacon_frontmark_combined_header.png)\n",
    "# Equity Stochastic Volatility Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# all necessary imports and global definitions\n",
    "import pyvacon.analytics as analytics\n",
    "import datetime as dt\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "from pylab import rcParams\n",
    "import math\n",
    "import copy\n",
    "import pyvacon.tools.converter as converter\n",
    "import pyvacon.tools.enums as enums\n",
    "import pyvacon.marketdata.plot as mkt_plot #import module for plotting functionality\n",
    "import pyvacon.marketdata.converter as mkt_converter\n",
    "import pyvacon.instruments.converter as ins_converter\n",
    "import pyvacon.pricing.tools as pricing_tools\n",
    "import pyvacon.models.plot as model_plot\n",
    "import pyvacon.models.tools as model_tools\n",
    "import pyvacon.models.converter as model_converter\n",
    "import qgrid\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import Markdown, display\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "%config Application.log_level=\"INFO\"\n",
    "\n",
    "#the next lin is a jupyter internal command to show the matplotlib graphs within the notebook\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "# define global variables\n",
    "refdate = analytics.ptime(2017,8,14,15,30,0) #dates which enters analytics objects must be analytics ptimes.\n",
    "num_sims = 40000\n",
    "model_dict = {}\n",
    "models = {}\n",
    "\n",
    "calibrate_stoch_vol = False\n",
    "calibrate_stoch_loc_vol = True\n",
    "simulate_paths = True\n",
    "\n",
    "# test implied volatility surface data which is used as calibration target\n",
    "underlying={\n",
    "    'TEST':{\n",
    "            'SPOT': 100,\n",
    "            'DIVIDENDS': \n",
    "                  pd.DataFrame({ \n",
    "                      'EXDATES': [dt.datetime(2018,1,1), dt.datetime(2019,1,1), dt.datetime(2020,1,1), dt.datetime(2021,1,1)],\n",
    "                      'PAYDATES': [dt.datetime(2018,1,1), dt.datetime(2019,1,1), dt.datetime(2020,1,1), dt.datetime(2021,1,1)],\n",
    "                      'CASH': [0.0, 0.0, 0.0, 0.0],\n",
    "                      'YIELD': [0.0, 0.0, 0.0, 0.0],\n",
    "                      'TAX': [0.0, 0.0, 0.0, 0.0]\n",
    "                  }),\n",
    "            'BORROW':\n",
    "              {\n",
    "                'DATES' : [dt.datetime(2018,1,1), dt.datetime(2020,1,1)],\n",
    "                'RATES' : [0.0, 0.0]\n",
    "              },\n",
    "            'VOLATILITY':{\n",
    "                  'TYPE': 'SSVI',\n",
    "                  'EXPIRIES': [10, 100, 365, 730], \n",
    "                  'ATMVOLS': [0.15, 0.17, 0.19, 0.2], \n",
    "                  'RHO': -0.65, \n",
    "                  'ETA': 0.8, \n",
    "                  'GAMMA': 0.5\n",
    "                  }\n",
    "              }\n",
    "}\n",
    "\n",
    "discount = {\n",
    "    'EUR':{\n",
    "        'DATES' : [dt.datetime(2018,1,1), dt.datetime(2020,1,1)],\n",
    "        'RATES' : [0.00, 0.00]\n",
    "    }\n",
    "}\n",
    "\n",
    "vol = mkt_converter.vol_from_dict(underlying, discount, 'TEST', 'EUR', refdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stochastic Volatility Models\n",
    "As the name indicates in stochastic volatility models the volatility of the spot is also a stochastic process. Most of them have the form\n",
    "$$ dS = \\mu S dt + \\sigma(S,t) S W_S $$\n",
    "where $\\sigma(S,t)$ is also described by a stochastic process. Since we are using the Bühler model, we assume without loss of generality $\\mu = 0$ and $S(0)=1.0$.\n",
    "\n",
    "There are a lot of different models and we will concentrate on the Heston and Scott-Chesney models:\n",
    "- **Heston**\n",
    "- **Scott-Chesney**\n",
    "- Stein and Setin/Schöble Zhu\n",
    "- Hull-White\n",
    "- Hagan\n",
    "\n",
    "In the next subsection we briefly describe the models and create them as pyvacon objects.\n",
    "(See  [StochasticVolatilityModels-PastPresentAndFuture](https://jaeckel.000webhostapp.com/StochasticVolatilityModels-PastPresentAndFuture.pdf) for a discussion of all of the above models and more details)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Heston\n",
    "\\begin{align}\n",
    "dS = \\mu S dt +\\sqrt{v}SdW_S \\\\\n",
    "dv = \\kappa(\\theta-v)dt+\\alpha\\sqrt{v}dW_v \\\\\n",
    "<dW_s,dW_v> = \\rho\n",
    "\\end{align}\n",
    "Volatility may become zero unless the parameters are such that the (Feller) condition\n",
    "\\begin{align}\n",
    "    \\kappa\\theta >\\frac{1}{2}\\alpha^2\n",
    "\\end{align}\n",
    "holds true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# set Heston parameter\n",
    "heston_ref =  {'OBJ_ID': 'HESTON', \n",
    "               'TYPE': 'HESTON', \n",
    "               'S0': 1.0, \n",
    "               'KAPPA': 6.602490036240081, \n",
    "               'THETA': 0.02798645471115531, \n",
    "               'ALPHA': 0.8287155390363634, \n",
    "               'V0': 0.03280615553884353, \n",
    "               'RHO': -0.7760343895576935}\n",
    "model_dict['HESTON'] = heston_ref\n",
    "models['HESTON']  = model_converter.stochvolmodel_from_dict(model_dict['HESTON'], refdate)\n",
    "\n",
    "if False: #include a Heston with zero vol-of-variance to test for local volatility\n",
    "    models['HESTON_FLAT_VOL'] = model_converter.stochvolmodel_from_dict({ 'OBJ_ID': 'HESTON_FLAT_VOL',\n",
    "                    'TYPE': 'HESTON',\n",
    "                    'S0':1.0,\n",
    "                    'KAPPA':1.7961805947284033,\n",
    "                    'THETA': 0.0225015745510251115,\n",
    "                    'ALPHA': 0.0,\n",
    "                    'V0' : 0.0225015745510251115,\n",
    "                    'RHO': -0.8\n",
    "                  }, refdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compute implied vols\n",
    "expiries = [90, 180, 365]\n",
    "max_num_threads = 2\n",
    "xstrikes = np.arange(0.8, 1.2, 0.05)\n",
    "iv = model_tools.compute_implieds(expiries, models['HESTON'], num_sims, 365, np.arange(0.8, 1.2, 0.05), refdate, max_num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compute implied vols for shifted heston\n",
    "heston_new = copy.deepcopy(heston_ref)\n",
    "heston_new['KAPPA'] *= 1.0\n",
    "heston_new['THETA'] *= 0.50\n",
    "heston_new['ALPHA'] *= 1.0\n",
    "heston_new['V0'] *= 1.0\n",
    "heston_new['RHO'] *= 1.0\n",
    "heston_new = model_converter.stochvolmodel_from_dict(heston_new, refdate)\n",
    "iv_shifted = model_tools.compute_implieds(expiries, heston_new, num_sims, 365, xstrikes, refdate, max_num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot implieds of the two heston models\n",
    "rcParams['figure.figsize'] = 20, 4\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(xstrikes, iv[0,:], '-x', label='unshifted')\n",
    "plt.plot(xstrikes, iv_shifted[0,:], '-x', label='shifted')\n",
    "plt.legend()\n",
    "plt.title('90 days iv')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(xstrikes, iv[1,:], '-x', label='unshifted')\n",
    "plt.plot(xstrikes, iv_shifted[1,:], '-x', label='shifted')\n",
    "plt.legend()\n",
    "plt.title('180 days iv')\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(xstrikes, iv[2,:], '-x', label='unshifted')\n",
    "plt.plot(xstrikes, iv_shifted[2,:], '-x', label='shifted')\n",
    "plt.legend()\n",
    "plt.title('1 yr iv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scott-Chesney\n",
    "\\begin{align}\n",
    "dS = \\mu S dt +e^ySdW_S\\\\\n",
    "dy = \\kappa(\\theta - y)dt + \\alpha dW_y \\\\\n",
    "<dW_s,dW_v> = \\rho\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#setup model parameter\n",
    "model_dict['SCOTT_CHESNEY'] = {'OBJ_ID': 'SCOTT_CHESNEY', \n",
    "                               'TYPE': 'SCOTT_CHESNEY', \n",
    "                               'S0': 1.0, \n",
    "                               'KAPPA': 0.08437217322463386, \n",
    "                               'THETA': -9.812444706126039, \n",
    "                               'ALPHA': 1.1505654142647475, \n",
    "                               'V0': -1.8839711373791805, \n",
    "                               'RHO': -0.7726808266170035}\n",
    "models['SCOTT_CHESNEY'] = model_converter.stochvolmodel_from_dict(model_dict['SCOTT_CHESNEY'], refdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compute implied vols\n",
    "expiries = [90, 180, 365]\n",
    "max_num_threads = 2\n",
    "xstrikes = np.arange(0.8, 1.2, 0.05)\n",
    "iv_sc = model_tools.compute_implieds(expiries, models['SCOTT_CHESNEY'], num_sims, 365, np.arange(0.8, 1.2, 0.05), refdate, max_num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compute implied vols for shifted Scot Chesney\n",
    "sc_new = copy.deepcopy(model_dict['SCOTT_CHESNEY'])\n",
    "sc_new['KAPPA'] *= 7.0\n",
    "sc_new['THETA'] *= 0.50\n",
    "sc_new['ALPHA'] *= 3.0\n",
    "sc_new['V0'] *= 1.0\n",
    "sc_new['RHO'] *= 0.5\n",
    "sc_new = model_converter.stochvolmodel_from_dict(sc_new, refdate)\n",
    "iv_sc_shifted = model_tools.compute_implieds(expiries, sc_new, num_sims, 365, xstrikes, refdate, max_num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot implieds of the two heston models\n",
    "rcParams['figure.figsize'] = 20, 4\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(xstrikes, iv_sc[0,:], '-x', label='unshifted')\n",
    "plt.plot(xstrikes, iv_sc_shifted[0,:], '-x', label='shifted')\n",
    "plt.legend()\n",
    "plt.title('90 days iv')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(xstrikes, iv_sc[1,:], '-x', label='unshifted')\n",
    "plt.plot(xstrikes, iv_sc_shifted[1,:], '-x', label='shifted')\n",
    "plt.legend()\n",
    "plt.title('180 days iv')\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(xstrikes, iv_sc[2,:], '-x', label='unshifted')\n",
    "plt.plot(xstrikes, iv_sc_shifted[2,:], '-x', label='shifted')\n",
    "plt.legend()\n",
    "plt.title('1 yr iv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model calibration\n",
    "Each stochastic volatility model can be calibrated to given implied volatility surface. Here, for a defined set of expiries $T_j$, $1\\leq j\\leq M$, and X-Strikes $X_i$, $1\\leq i\\leq N$, call prices $C_{i,j}$ are computed and the model parameters are determined (by an optimization algorithm) such that the error function \n",
    "$$\n",
    "E(x) = \\sum_{i,j}(C_{i,j}-\\tilde C_{i,j})^2,\n",
    "$$\n",
    "where $\\tilde C_{i,j}$ is the model call prices computed by Monte Carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     20,
     27,
     34,
     41,
     45
    ]
   },
   "outputs": [],
   "source": [
    "#model calibration\n",
    "model_id = 'SCOTT_CHESNEY' # SCOTT_CHESNEY HESTON\n",
    "model_tools.logger.setLevel(logging.INFO)\n",
    "def calibrate():\n",
    "    model = models[model_id]\n",
    "    strikes = [0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "    expiries = [90, 180, 365]\n",
    "    n_sims = 8000 # number of Monte Carlo simulations used to compute the model call prices \n",
    "    n_steps_per_year = 365\n",
    "    max_num_threads = 2\n",
    "    calibrator = model_tools.BuehlerStochVolCalibrator(refdate, expiries, strikes, vol, model,'dummy', n_sims, n_steps_per_year, max_num_threads)\n",
    "\n",
    "    #setup parameter mapping\n",
    "    def heston_param_mapping(x,y):\n",
    "        x[0] = abs(y[0])\n",
    "        x[1] = abs(y[1])\n",
    "        x[2] = abs(y[2])\n",
    "        x[3] = abs(y[3])\n",
    "        x[4] = 1.95*np.arctan(y[4])/np.pi\n",
    "        \n",
    "    def heston_inv_param_mapping(x,y):\n",
    "        x[0] = y[0]\n",
    "        x[1] = y[1]\n",
    "        x[2] = y[2]\n",
    "        x[3] = y[3]\n",
    "        x[4] = np.tan(y[4]*np.pi/1.95)\n",
    "\n",
    "    def scott_chesney_mapping(x,y):\n",
    "        x[0] = y[0]\n",
    "        x[1] = abs(y[1])\n",
    "        x[2] = abs(y[2])\n",
    "        x[3] = y[3]\n",
    "        x[4] = 1.95*np.arctan(y[4])/np.pi\n",
    "\n",
    "    def scott_chesney_inv_mapping(x,y):\n",
    "        x[0] = y[0]\n",
    "        x[1] = abs(y[1])\n",
    "        x[2] = abs(y[2])\n",
    "        x[3] = y[3]\n",
    "        x[4] = np.tan(y[4]*np.pi/1.95)\n",
    "\n",
    "    param_mappings = {\n",
    "        'HESTON' :  heston_param_mapping,\n",
    "        'SCOTT_CHESNEY' : scott_chesney_mapping\n",
    "    }  \n",
    "    inv_param_mappings = {\n",
    "        'HESTON' :  heston_inv_param_mapping,\n",
    "        'SCOTT_CHESNEY' : scott_chesney_inv_mapping\n",
    "    }  \n",
    "\n",
    "    #calibrate\n",
    "    startvalues = analytics.vectorDouble()\n",
    "    model.getParameters(startvalues)\n",
    "    optim_options = {'xtol': 1e-5, 'ftol': 1e-5, 'maxiter': 150, 'maxfev': 1500, 'disp': True}\n",
    "    \n",
    "    print(model_dict[model_id])\n",
    "    inv_param_mappings[model_id](startvalues, startvalues)\n",
    "    calibrator.calibrate(startvalues, param_mappings[model_id], 'Nelder-Mead', optim_options) # Powell, Nelder-Mead, BFGS\n",
    "    model.getParameters(startvalues)\n",
    "    model_converter.stochvolmodel_to_dict(model, model_dict[model_id])\n",
    "    print(model_dict[model_id])\n",
    "    \n",
    "    return calibrator\n",
    "    #output calibrated parameters\n",
    "if False: calibrator = calibrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#plot calibration errors\n",
    "if False : calibrator.plot_error_vols( [0,1,2], True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Local Volatility\n",
    "$$ dS/S = \\mu dt + \\sigma(S,t)vdW_t,$$\n",
    "$$ dv = \\nu(v,t) dt + \\sigma^v(v,t) dW^v_t$$\n",
    "where $\\sigma(S,t)$ is the stochastic-local-volatility calibrated so that the model perfectly fits a given volatility surface.\n",
    "\n",
    "The stochastic-local volatility may be derived from the leverage function $l(S,t)= E\\left(v^2\\mid S_t=S\\right)$ and the local volatility $\\sigma^{lv}(S,t)$ by\n",
    "$$\n",
    "\\sigma(S,t) = \\sigma^{lv}(S,t) = \\frac{\\sigma^{lv}(S,t)}{\\sqrt{l(S,t)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrating the stochastic local volatility function\n",
    "- Time discretization $t_i$, $1\\leq i \\leq N$\n",
    "- $l(S_0,0) = \\frac{\\sigma^{lv}(S_0,0)}{v(0)}$\n",
    "\n",
    "- Use Euler discretized MC with regression to derive leverage function/local vol of process\n",
    "    - $ v(t_{i+1}) = \\nu(v(t_i,t_i))(t_{i+1}-t_i) + \\sigma^v(v(t_i),t_i)\\varepsilon_i $\n",
    "    - $S(t_{i+1}) = S(t_i)\\mu(t_{i+1}-t_i) + \\sigma(S(t_i), t_i)v(t_i)\\tilde \\varepsilon_i$\n",
    "- Use simulated values $S(t_{i+1})$ and $ v(t_{i+1})$ to estimate \n",
    "$$l\\left(S(t_{i+1}),t_{i+1}\\right)= E\\left(v(t_{i+1})^2\\mid S_{t_{i+1}}=S_{t_i}\\right)$$\n",
    "via regression.\n",
    "- Also possible to calibrate to a stochastic volatility process of higher dimensions\n",
    "\n",
    "Alternative: PDE, but numerically much more difficult and not very generic, see [here](https://www.rivacon.com/wp-content/uploads/2017/09/stoch_local_vol.pdf) for an example for the Heston model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "#calibrate stochastic local volatility\n",
    "if calibrate_stoch_loc_vol:\n",
    "    time_grid = analytics.vectorDouble(pl.frange(1.0/365.0, 3.0, 1.0/365.0))\n",
    "    stoch_local_vol ={}\n",
    "    def get_regression_parameter():\n",
    "        rbf_param =  analytics.RBFRegressionParameter()\n",
    "        rbf_param.nCenters = 25\n",
    "        rbf_param.includeLinearFunctions = False\n",
    "        rbf_param.scalingFactor = 0.01\n",
    "\n",
    "        polynom_param = analytics.PolynomialRegression1DParameter('')\n",
    "        polynom_param.degree = 20\n",
    "\n",
    "        pcw_linear_param = analytics.PiecewiseLinearRegression1DParameter('')\n",
    "        pcw_linear_param.nGridPoints = 80\n",
    "        pcw_linear_param.smoothnessPenalty = 0.000001\n",
    "        \n",
    "        return pcw_linear_param\n",
    "\n",
    "    def calibrate_stoch_loc_vol():\n",
    "        #analytics.setLogLevel('INFO')\n",
    "        leverage_calib_param = analytics.StochLocalVolFunctionCalibratorParameter()\n",
    "        leverage_calib_param.pgParam = analytics.PathGeneratorParameter()\n",
    "        leverage_calib_param.pgParam.numberOfSimulations = 200000\n",
    "        leverage_calib_param.regressionParam = get_regression_parameter()\n",
    "        return analytics.StochLocalVolFunctionCalibrator.calibrate(refdate, leverage_calib_param, time_grid, stoch_vol_model, vol)\n",
    "    \n",
    "    for model in ['HESTON', 'SCOTT_CHESNEY']: #\n",
    "        stoch_vol_model = models[model]\n",
    "        stoch_local_vol[model] = calibrate_stoch_loc_vol()\n",
    "        models[model + '_LV'] = analytics.StochasticLocalVolatility(models[model], stoch_local_vol[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "#plot stochastic local volatility\n",
    "def plot_stoch_loc_vol(time_slices, spot_slices, stoch_local_vol):\n",
    "    rcParams['figure.figsize'] = 12, 5\n",
    "    spot_grid = analytics.vectorDouble(pl.frange(0.50, 1.5,0.01))\n",
    "    lev_surf = stoch_local_vol.eval(time_grid, spot_grid)\n",
    "    plt.subplot(1,2,1)\n",
    "    for i in range(len(time_slices)):\n",
    "        plt.plot(spot_grid,lev_surf[time_slices[i]], '-x', label='ttm %.2f' % time_grid[time_slices[i]])\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('stochastic local volatility')\n",
    "    plt.legend()\n",
    "    plt.title('spot slices')\n",
    "    plt.subplot(1,2,2)\n",
    "    for i in range(len(spot_slices)):\n",
    "        timeline = []\n",
    "        for j in range(len(time_grid)):\n",
    "            \n",
    "            timeline.append(lev_surf[j][spot_slices[i]])\n",
    "        plt.plot(time_grid, timeline, '-o', label = 'spot ' + str(spot_grid[spot_slices[i]]))\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel('stochastic local volatility')\n",
    "    plt.title('time slices')\n",
    "  \n",
    "    plt.legend()\n",
    "\n",
    "plot_stoch_loc_vol([50, 180, 365], [0, 50, 99], stoch_local_vol['SCOTT_CHESNEY']) # 'SCOTT_CHESNEY' HESTON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulating Paths\n",
    "All tools to analyze the models are based on simulated paths. Therefore we first have to simulate the model of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# simulate paths for all models using the analytics.ModelLab\n",
    "model_labs = {}\n",
    "simtimes_p = range(1,3*365)\n",
    "simtimes = converter.createPTimeList(refdate, simtimes_p)\n",
    "max_num_threads = 2\n",
    "def simulate_paths():\n",
    "    ntimesteps_per_year = 365\n",
    "    for key, model in models.items():\n",
    "        tmp = analytics.ModelLab(model, refdate)\n",
    "        tmp.simulate(simtimes, num_sims, ntimesteps_per_year, max_num_threads) \n",
    "        model_labs[key] = tmp\n",
    "start_time = time.time()\n",
    "if simulate_paths: simulate_paths()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# calibration errors\n",
    "def plot_implieds_expiry(expiry_index, stoch_vol_model):\n",
    "    strikes =  pl.frange(0.8,1.20, 0.020)\n",
    "    vols = []\n",
    "    vols_stoch_vol = []\n",
    "    call_prices = model_tools.compute_statistics(model_labs[stoch_vol_model + '_LV'], strikes, expiry_index, 0, lambda x, y: max(x-y,0.0))\n",
    "    call_prices_stoch_vol = model_tools.compute_statistics(model_labs[stoch_vol_model], strikes, expiry_index, 0, lambda x, y: max(x-y,0.0))\n",
    "    dc = analytics.DayCounter(enums.DayCounter.ACT365_FIXED)\n",
    "    expiry_yf = dc.yf(refdate, simtimes[expiry_index])\n",
    "    for i in range(len(call_prices)):\n",
    "        vols.append(analytics.calcImpliedVol(call_prices[i], strikes[i], expiry_yf, 1.0, 1.0, 'C'))\n",
    "        vols_stoch_vol.append(analytics.calcImpliedVol(call_prices_stoch_vol[i], strikes[i], expiry_yf, 1.0, 1.0, 'C'))\n",
    "    vol_ref = []\n",
    "    for i in strikes:\n",
    "        vol_ref.append(vol.calcImpliedVol(refdate, simtimes[expiry_index], i))\n",
    "    plt.plot(strikes, vol_ref, '-o', label='reference')\n",
    "    plt.plot(strikes, vols_stoch_vol, '-x', label=stoch_vol_model)\n",
    "    plt.plot(strikes, vols, '-x', label=stoch_vol_model+'_LV')\n",
    "    plt.title('expiry ' + str(expiry_index))\n",
    "    plt.legend()\n",
    "    \n",
    "def plot_implieds_expiries():\n",
    "    plt.subplot(2,4,1)\n",
    "    plot_implieds_expiry(180, 'HESTON')\n",
    "    plt.subplot(2,4,2)\n",
    "    plot_implieds_expiry(365, 'HESTON')\n",
    "    plt.subplot(2,4,3)\n",
    "    plot_implieds_expiry(365+180, 'HESTON')\n",
    "    plt.subplot(2,4,4)\n",
    "    plot_implieds_expiry(2*365, 'HESTON')\n",
    "    plt.subplot(2,4,5)\n",
    "    plot_implieds_expiry(180, 'SCOTT_CHESNEY')\n",
    "    plt.subplot(2,4,6)\n",
    "    plot_implieds_expiry(365, 'SCOTT_CHESNEY')\n",
    "    plt.subplot(2,4,7)\n",
    "    plot_implieds_expiry(365+180, 'SCOTT_CHESNEY')\n",
    "    plt.subplot(2,4,8)\n",
    "    plot_implieds_expiry(2*365, 'SCOTT_CHESNEY')\n",
    "\n",
    "rcParams['figure.figsize'] = 24, 8\n",
    "plot_implieds_expiries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility and Variance Options\n",
    "### Variance options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# price variance and volatility options\n",
    "var_call_prices = {}\n",
    "var_strikes = pl.frange(0.7, 1.3, 0.05)\n",
    "rlzd_var = {}\n",
    "\n",
    "def price_var_option_implieds(strikes,  n_time):\n",
    "    result_var = {}\n",
    "    result_vol = {}\n",
    "    for key, model_lab in model_labs.items():\n",
    "        sims, sims_vol = model_tools.compute_realized_vol_var(model_lab, n_time)\n",
    "        fwd = np.mean(sims)\n",
    "        fwd_vol = np.mean(sims_vol)\n",
    "        #print(fwd)\n",
    "        vols = []\n",
    "        vols_vol = []\n",
    "        for i in range(len(strikes)):\n",
    "            try:\n",
    "                vols.append(analytics.calcImpliedVol(np.mean([max(x-strikes[i]*fwd,0.0) for x in sims]), strikes[i]*fwd, n_time/365.0, 1.0, fwd, 'C'))\n",
    "            except RuntimeError:\n",
    "                vols.append(0)\n",
    "            try:\n",
    "                vols_vol.append(analytics.calcImpliedVol(np.mean([max(x-strikes[i]*fwd_vol,0.0) for x in sims_vol]), strikes[i]*fwd_vol, n_time/365.0, 1.0, fwd_vol, 'C'))\n",
    "            except:\n",
    "                vols_vol.append(0)\n",
    "        result_var[key] = vols\n",
    "        result_vol[key] = vols_vol\n",
    "    return result_var, result_vol\n",
    "n_time = 300\n",
    "var_call_vols, vol_call_vols = price_var_option_implieds(var_strikes, n_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# plot implied vols of Call options on variance and volatility\n",
    "plt.subplot(1,2,1)\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "for model in ['HESTON',  'SCOTT_CHESNEY', 'HESTON_LV', 'SCOTT_CHESNEY_LV']:\n",
    "    plt.plot(var_strikes, var_call_vols[model], '-x', label = model)\n",
    "plt.xlabel('relative (to fwd) strikes')\n",
    "plt.ylabel('implied vol of call option on variance')\n",
    "plt.legend()\n",
    "plt.title('Calls on realized variance')\n",
    "plt.subplot(1,2,2)\n",
    "for model in ['HESTON',  'SCOTT_CHESNEY', 'HESTON_LV', 'SCOTT_CHESNEY_LV']:\n",
    "    plt.plot(var_strikes, vol_call_vols[model], '-x', label = model)\n",
    "plt.xlabel('relative (to fwd) strikes')\n",
    "plt.ylabel('implied vol of call option on vol')\n",
    "plt.legend()\n",
    "plt.title('Calls on realized volatility')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Start Options\n",
    "The payoff of forward start options is fixed at a future time (here typically the strike is fixed w.r.t. a spot at a certain time).\n",
    "### Forward Start Call\n",
    "European Call where the strike is fixed relative to a future spot, i.e.\n",
    "$$ V(S_T) = \\max(S_T-k\\cdot S_{T_0},0) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# compute prices\n",
    "def price_fwd_start_call(model_lab, timeindex_fixing, timeindex_expiry, strikes):\n",
    "    prev_spots = analytics.vectorDouble()\n",
    "    curr_spots = analytics.vectorDouble()\n",
    "    model_lab.getTimeSlice(prev_spots, timeindex_fixing, 0)\n",
    "    model_lab.getTimeSlice(curr_spots, timeindex_expiry, 0)\n",
    "    result = []\n",
    "    for strike in strikes:\n",
    "        prices = np.zeros(prev_spots.size())\n",
    "        for j in range(len(prev_spots)):\n",
    "            prices[j] += max(curr_spots[j] - strike*prev_spots[j], 0.0)\n",
    "        result.append(np.mean(prices))\n",
    "    return result\n",
    "\n",
    "strikes = pl.frange(0.7,1.3, 0.0125)\n",
    "t_fixing = 365\n",
    "t_expiry = 365 + 365\n",
    "fwd_start_call_prices = {}\n",
    "for model in models:\n",
    "    fwd_start_call_prices[model] = price_fwd_start_call(model_labs[model], t_fixing, t_expiry, strikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot prices\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "for model in ['HESTON', 'HESTON_LV', 'SCOTT_CHESNEY', 'SCOTT_CHESNEY_LV']:\n",
    "    plt.plot(strikes, fwd_start_call_prices[model], '-x', label = model)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Start Call Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot prices\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "for model in ['HESTON', 'HESTON_LV', 'SCOTT_CHESNEY', 'SCOTT_CHESNEY_LV']:\n",
    "    tmp = []\n",
    "    for i in range(len(strikes)-1):\n",
    "        tmp.append(fwd_start_call_prices[model][i]- fwd_start_call_prices[model][i+1])\n",
    "    plt.plot(strikes[0:len(strikes)-1], tmp , '-x', label = model)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Start Digital Call\n",
    "$$ V(S_{T}) = \\left\\{ \\begin{array}{l} 1 \\mbox{ if } \\frac{S_{T}}{S_{T_0}} > K_{rel} \\\\\n",
    "                            0 \\mbox{ otherwise } \\end{array} \\right.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compute prices\n",
    "def price_fwd_start_digital(model_lab, timeindex_fixing, timeindex_expiry, strikes):\n",
    "    prev_spots = analytics.vectorDouble()\n",
    "    curr_spots = analytics.vectorDouble()\n",
    "    model_lab.getTimeSlice(prev_spots, timeindex_fixing, 0)\n",
    "    model_lab.getTimeSlice(curr_spots, timeindex_expiry, 0)\n",
    "    result = []\n",
    "    for strike in strikes:\n",
    "        prices = np.zeros(prev_spots.size())\n",
    "        for j in range(len(prev_spots)):\n",
    "                if curr_spots[j] > strike*prev_spots[j]:\n",
    "                    prices[j] += 1.0\n",
    "        prices = np.maximum(prices, 0.0)\n",
    "        result.append(np.mean(prices))\n",
    "    return result\n",
    "\n",
    "strikes = pl.frange(0.7,1.3, 0.0125)\n",
    "t_fixing = 365\n",
    "t_expiry = 365 + 365\n",
    "fwd_start_digital_prices = {}\n",
    "for model in models:\n",
    "    fwd_start_digital_prices[model] = price_fwd_start_digital(model_labs[model], t_fixing, t_expiry, strikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot prices\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "for model in ['HESTON', 'HESTON_LV', 'SCOTT_CHESNEY', 'SCOTT_CHESNEY_LV']:\n",
    "    plt.plot(strikes, fwd_start_digital_prices[model], '-x', label = model)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cliquets\n",
    "Cliquet options payoff is a function of relative returns.\n",
    "Different types are (the interest reader is referred to [here](https://mathfinance.com/wp-content/uploads/2017/06/20100822-kilin-nalholm-wystup-costOfVol.pdf) for a detailed discussion and prices for different cliquets):\n",
    "- Reverse Cliquets\n",
    "- Napoleon\n",
    "- Accumulator\n",
    "- Call Spread Cliquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Cliquet\n",
    "The reverse cliquet pays\n",
    "$$ P =  \\max \\left( C+ \\sum_{i=0}^{N-1} r_i^-, 0\\right)$$\n",
    "where $ r_i = \\frac{S_{T_{i+1}}-S_{T_i}}{S_{T_i}} $ and $r_i^-=\\min(r_i,0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#compute prices\n",
    "def price_reverse_cliquet(model_lab, max_coupons, num_days_period, num_days_expiry):\n",
    "    prev_spots = analytics.vectorDouble()\n",
    "    curr_spots = analytics.vectorDouble()\n",
    "    model_lab.getTimeSlice(prev_spots, 0, 0)\n",
    "    result = []\n",
    "    prices = np.zeros(prev_spots.size())\n",
    "    for i in range(num_days_period,num_days_expiry,num_days_period):\n",
    "        model_lab.getTimeSlice(curr_spots, i, 0)\n",
    "        for j in range(len(prev_spots)):\n",
    "            prices[j] += min((curr_spots[j]-prev_spots[j])/prev_spots[j], 0)\n",
    "        prev_spots.swap(curr_spots)\n",
    "    for C in max_coupons:\n",
    "        #tmp = np.maximum(prices + C, 0.0)\n",
    "        result.append(np.mean(np.maximum(prices + C, 0.0)))\n",
    "    return result\n",
    "\n",
    "max_coupons = pl.frange(0.1,0.6, 0.1)\n",
    "\n",
    "reverse_cliquet_prices = {}\n",
    "for model in models:\n",
    "    reverse_cliquet_prices[model] = price_reverse_cliquet(model_labs[model], max_coupons, 30, 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot prices\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "for model in ['HESTON', 'HESTON_LV', 'SCOTT_CHESNEY', 'SCOTT_CHESNEY_LV']:\n",
    "    plt.plot(max_coupons, reverse_cliquet_prices[model], '-x', label = model)\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('price')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Napoleon\n",
    "The payoff is a combo of payoffs of the form\n",
    "$$ P =  \\max \\left( C+ \\min_i r_i, 0\\right)$$\n",
    "where $ r_i = \\frac{S_{T_{i+1}}-S_{T_i}}{S_{T_i}} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#compute prices\n",
    "def price_simple_napoleon(model_lab, coupons, num_days_period, num_days_expiry):\n",
    "    prev_spots = analytics.vectorDouble()\n",
    "    curr_spots = analytics.vectorDouble()\n",
    "    model_lab.getTimeSlice(prev_spots, 0, 0)\n",
    "    result = []\n",
    "    prices = np.full(prev_spots.size(), 10000000.1)\n",
    "    for i in range(num_days_period,num_days_expiry,num_days_period):\n",
    "        model_lab.getTimeSlice(curr_spots, i, 0)\n",
    "        for j in range(len(prev_spots)):\n",
    "            prices[j] = min((curr_spots[j]-prev_spots[j])/prev_spots[j], prices[j])\n",
    "        prev_spots.swap(curr_spots)\n",
    "    for C in coupons:    \n",
    "        tmp = np.maximum(prices+C, 0.0)\n",
    "        result.append(np.mean(tmp))\n",
    "    return result\n",
    "\n",
    "coupons = pl.frange(0.04,0.12, 0.01)\n",
    "\n",
    "napoleon_prices = {}\n",
    "for model in models:\n",
    "    napoleon_prices[model] = price_simple_napoleon(model_labs[model], coupons, 30, 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot prices\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "for model in ['HESTON', 'HESTON_LV', 'SCOTT_CHESNEY', 'SCOTT_CHESNEY_LV']:\n",
    "    plt.plot(coupons, napoleon_prices[model], '-x', label = model)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulator\n",
    "Payoff is given by\n",
    "$$ P = \\max\\left(0, \\sum_{i=0}^{N-1}\\max\\left(\\min(r_i, \\mbox{cap}), \\mbox{floor}  \\right) \\right)$$\n",
    "where $ r_i = \\frac{S_{T_{i+1}}-S_{T_i}}{S_{T_i}} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#compute prices\n",
    "def price_accumulator(model_lab, cap, floor, num_days_period, num_days_expiry):\n",
    "    prev_spots = analytics.vectorDouble()\n",
    "    curr_spots = analytics.vectorDouble()\n",
    "    model_lab.getTimeSlice(prev_spots, 0, 0)\n",
    "    result = []\n",
    "    prices = np.full(prev_spots.size(), 0.0)\n",
    "    for i in range(num_days_period,num_days_expiry,num_days_period):\n",
    "        model_lab.getTimeSlice(curr_spots, i, 0)\n",
    "        for j in range(len(prev_spots)):\n",
    "            prices[j] += max(min((curr_spots[j]-prev_spots[j])/prev_spots[j], cap), floor)\n",
    "        prev_spots.swap(curr_spots)\n",
    "    tmp = np.maximum(prices, 0.0)\n",
    "    return np.mean(tmp)\n",
    "\n",
    "floor = -0.01\n",
    "caps = pl.frange(0.006,0.02, 0.002)\n",
    "\n",
    "accumulator_prices = {}\n",
    "for model in models:\n",
    "    accumulator_prices[model] = []\n",
    "    for cap in caps:\n",
    "        accumulator_prices[model].append(price_accumulator(model_labs[model], cap, floor, 30, 365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot prices\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "for model in ['HESTON', 'HESTON_LV', 'SCOTT_CHESNEY', 'SCOTT_CHESNEY_LV']:\n",
    "    plt.plot(caps, accumulator_prices[model], '-x', label = model)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globally capped, locally floored Cliquets\n",
    "-monthly resetting, locally capped, globally floored Call\n",
    "-Spot=100 ->Annahme preis < 1% bei local vol, stoch vol teurer > 2%\n",
    "\n",
    "$\\max(\\sum_{i=1}^{12} (C_{S(i-1)}-P_{S(i-1)}-C_{1.04*S(i-1)}),0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "#price\n",
    "def price_cliquet(model_lab, cap=0.04):\n",
    "    prev_spots = analytics.vectorDouble()\n",
    "    curr_spots = analytics.vectorDouble()\n",
    "    model_lab.getTimeSlice(prev_spots, 0, 0)\n",
    "    prices = np.zeros(prev_spots.size())\n",
    "    for i in range(30,361,30):\n",
    "        model_lab.getTimeSlice(curr_spots, i, 0)\n",
    "        for j in range(len(prev_spots)):\n",
    "            prices[j] += min(curr_spots[j]-prev_spots[j], cap*prev_spots[j])\n",
    "        prev_spots.swap(curr_spots)\n",
    "    prices = np.maximum(prices, 0.0)\n",
    "    return np.mean(prices)\n",
    "    \n",
    "cliquet_prices = {}\n",
    "for model in models:\n",
    "    cliquet_fixing_index = 120\n",
    "    cliquet_prices[model] = price_cliquet(model_labs[model])\n",
    "    \n",
    "print(str(cliquet_prices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot single paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plot.paths(model_labs['SCOTT_CHESNEY'], range(10,20),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lab = model_labs['SCOTT_CHESNEY'] # SCOTT_CHESNEY\n",
    "ntimepoint = 5*300\n",
    "spot = analytics.vectorDouble()\n",
    "variance = analytics.vectorDouble()\n",
    "for ntimepoint in [180, 360]:\n",
    "    model_lab.getTimeSlice(spot, ntimepoint, 0)\n",
    "    model_lab.getTimeSlice(variance, ntimepoint, 1)\n",
    "    for i in range(len(variance)):\n",
    "        variance[i] = math.exp(2.0*variance[i])\n",
    "    plt.plot(spot, variance,'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bühler Model\n",
    "So far we assumed that $S(0) = 1.0$ and $\\mu = 0$. All results carry simply over to more realistic cases including cash dividends using the Bühler approach. Here, the spot is simply modeled by a so-called X-Process\n",
    "The volatility surfaces provided by the analytics library are parametrized w.r.t. the so-called X-strikes, i.e. one has to put in a strike w.r.t. the X-variable which is the driving process of the spot $S$, i.e.\n",
    "$$ S_t=(F_t-D_t)X_t+D_t$$\n",
    "where $F_t$ is the risky forward and $D_t$ the cash dividends, see [buehler](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1141877) for a more detailed discussion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "299px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "794px",
    "left": "0px",
    "right": "1533.47px",
    "top": "107px",
    "width": "245px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
