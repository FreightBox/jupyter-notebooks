{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook for Worst-of-DOP\n",
    "We model the worst-of down and out Put using the Rainbow-Specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvacon.analytics as analytics\n",
    "import pyvacon.tools.enums as enums\n",
    "import pyvacon.marketdata.testdata as mkt_testdata\n",
    "import pyvacon.environment as environment\n",
    "import pyvacon.models.tools as model_tools\n",
    "import pyvacon.tools.converter as converter\n",
    "import pyvacon.pricing.tools as pricing_tools\n",
    "import pyvacon.instruments.tools as ins_tools\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refdate = analytics.ptime(2017,7,1,0,0,0)\n",
    "\n",
    "env_test = environment.CalculationDataEnvironment()\n",
    "mkt_testdata.InterestRate.all_data(env_test)\n",
    "mkt_testdata.Equity.all_data(env_test)\n",
    "spot1 = env_test.mktman.getForwardCurve('DBK').value(refdate,refdate)\n",
    "spot2 = env_test.mktman.getForwardCurve('EON').value(refdate,refdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the specification\n",
    "In this section we show how to setup an Equita Monte Carlo product using the rainbow specification as provided by the nalytics library. \n",
    "### Payoff description\n",
    "A Worst-of Down&Out put is a put on the worst of a basket of stocks $S_i$, $1\\leq i\\leq N$, i.e. it has payoff\n",
    "$$\n",
    "P(S_1,...,S_N) = \\left\\{ \\begin{array}{l} (K-min_i(w_iS_i(T)))_+ \\mbox{ if }min_{0\\leq t\\leq T} min_i(w_iS_i(t))> b, \\\\ r \\mbox{ otherwise. }\\end{array}\\right. \n",
    "$$\n",
    "for a given barrierlevel $b$, rebate $r$ and strike $K$ and basket weights $w_i$.\n",
    "\n",
    "In the following we consider the case $K=100$, $r=0$, $b=80$ and the weights are chosen as $w_i=1.0/S_i(0)$.\n",
    "\n",
    "### The rainbow specification\n",
    "A rainbow specification consists of a set of barriers and rainbow basket underlyings.\n",
    "#### Rainbow basket underlying\n",
    "A rainbow basket underlying $u$ is constructed by first weighting the single constituents according to their basket weights, applying individual caps and floors. Then, a weighted sum of the capped and floored values is computed, these capped and floored single values are sorted from worst to best and are then summed up. In addition, one can define a forward start time together with forward start type, i.e. if the weights are adjusted by individual factors w.r.t. the single spots or by the basket value.\n",
    "To realize asian features one can also specify ficing dates together with different time aggregation types.\n",
    "#### Baskets\n",
    "Each barrier is defined by\n",
    "- A rainbow underlying id to the underlying on which the barrier is monitored.\n",
    "- A lower and upper level describing the range when the barrier is hit.\n",
    "- A start and end date describing the begin and end of the monitoring. If start equals end, a discrete barrier is constructed, if a list of monitoring dates is given, the barrier is only monitored at these discrete points.\n",
    "- A piecewise linear payoff if barrier is hit.\n",
    "- A piecewise linear payoff if barrier is not hit.\n",
    "- A flag whethr the barrier is active.\n",
    "- A list of barriers which are activated/inactivated by hitting this barrier.\n",
    "- A paydate deining when payoffs are paid. To define payoff at hit, the paydate has to be set before the barrir start date.\n",
    "\n",
    "### Example: Wof DOP\n",
    "#### The down & out barrier\n",
    "We first define the down and out barrier. This barrier pays zero at hit and must switch off the barrier which defines the final Put payoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrier_specs = analytics.vectorRainbowBarrierSpec(2)\n",
    "expiry = analytics.ptime(2018,7,1,0,0,0)\n",
    "barrier_start = refdate\n",
    "barrier_end = expiry\n",
    "obs_dates = analytics.vectorPTime()\n",
    "lower_level = -1000\n",
    "upper_level = 80\n",
    "udl_id = 0\n",
    "# switch of the final \"payoff\" barrier if barrier is hit\n",
    "barrier_num = analytics.vectorInt(1)\n",
    "barrier_num[0] = 1\n",
    "barrier_status = analytics.vectorBool(1)\n",
    "barrier_status[0] = False\n",
    "is_active = True\n",
    "hit_payoff_points = analytics.vectorDouble([0.0, 800000.0])\n",
    "hit_payoff_values = analytics.vectorDouble([0.0, 0.0])\n",
    "no_hit_payoff_points = analytics.vectorDouble()\n",
    "no_hit_payoff_values = analytics.vectorDouble()\n",
    "paydate = analytics.ptime(2000,1,1,0,0,0) #if paydate < startdate, then payoff is at hit\n",
    "barrier_specs[0] = analytics.RainbowBarrierSpec(barrier_start, barrier_end, obs_dates, lower_level, upper_level, udl_id, \n",
    "                                            barrier_num, barrier_status, is_active, hit_payoff_points, hit_payoff_values, \n",
    "                                              no_hit_payoff_points,  no_hit_payoff_values, paydate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The barrier to model the final Put payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refdate = analytics.ptime(2017,7,1,0,0,0)\n",
    "expiry = analytics.ptime(2018,7,1,0,0,0)\n",
    "barrier_start = expiry\n",
    "barrier_end = expiry\n",
    "obs_dates = analytics.vectorPTime()\n",
    "lower_level = -100000 #determine barrier levels so that barrier is hit with probability 1\n",
    "upper_level = 1000000\n",
    "udl_id = 0\n",
    "strike = 100\n",
    "barrier_num = analytics.vectorInt()\n",
    "barrier_status = analytics.vectorBool()\n",
    "hit_payoff_points = analytics.vectorDouble([0, strike, strike+1000000])\n",
    "hit_payoff_values = analytics.vectorDouble([0,0, 1000000])\n",
    "no_hit_payoff_points = analytics.vectorDouble()\n",
    "no_hit_payoff_values = analytics.vectorDouble()\n",
    "paydate = expiry\n",
    "barrier_specs[1] = analytics.RainbowBarrierSpec(barrier_start, barrier_end, obs_dates, lower_level, upper_level, udl_id, \n",
    "                                            barrier_num, barrier_status, is_active, hit_payoff_points, hit_payoff_values, \n",
    "                                              no_hit_payoff_points,  no_hit_payoff_values, paydate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The worst-of basket specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udls = analytics.vectorRainbowUdlSpec(1)\n",
    "basket = analytics.vectorString(['DBK','EON'])\n",
    "underlying_weights = analytics.vectorDouble([100.0/spot1,100.0/spot2])\n",
    "underlying_caps = analytics.vectorDouble()#[1000000,1000000])\n",
    "underlying_floors = analytics.vectorDouble()#[-10000,-100000])\n",
    "weights_after_sort = analytics.vectorDouble([1.0,0])\n",
    "basket_cap = analytics.getMaxDouble('');\n",
    "basket_floor = -analytics.getMaxDouble('');\n",
    "additive_offset = 0.0\n",
    "fixing_dates = analytics.vectorPTime()\n",
    "fwd_value_type = 'NONE' # set the fwd-start type (here: no fwd start), possible values: None, FwdStartSingle, FwdStartBasket, FloatingStrikeBasket\n",
    "fwd_time_agg_type = 'NONE' # set fwd start reference type, possible values: None, Min, Max, Mean\n",
    "type_str = 'WorstOf' # just for performance and validation, the type of basket: None, Basket, WorstOf, BestOf, General, BasketOfPerformances,\n",
    "                    #PerformanceOfBasket, Asian, LookbackBestOf, LookbackWorstOf\n",
    "fwd_start_fixings = analytics.vectorPTime()\n",
    "time_agg_type = 'None'\n",
    "floating_strike = 0\n",
    "udls[0] = analytics.RainbowUnderlyingSpec(basket, underlying_weights, underlying_caps, underlying_floors, weights_after_sort, \n",
    "                                          basket_cap, basket_floor, additive_offset, fwd_value_type, fwd_time_agg_type, \n",
    "                                          fwd_start_fixings,floating_strike,time_agg_type, fixing_dates, type_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = analytics.RainbowSpecification('WOF_DOP', 'DEKA', enums.SecuritizationLevel.NONE, 'EUR', expiry, barrier_specs, udls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricing with local volatility\n",
    "### Setting up PricingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_data = analytics.LocalVolMonteCarloPricingData()\n",
    "pricing_data.valDate = refdate\n",
    "pricing_data.spec = spec\n",
    "pricing_data.dsc = mkt_testdata.InterestRate.get_curve('EONIA', refdate)\n",
    "pricing_data.param = analytics.MonteCarloPricingParameter()\n",
    "pricing_data.param.mcParam.numberOfSimulations = 10000\n",
    "vols = analytics.vectorConstVolatilities(2)\n",
    "vols[0] = env_test.mktman.getVolatilitySurface('DBK')\n",
    "vols[1] = env_test.mktman.getVolatilitySurface('EON')\n",
    "pricing_data.vols = vols\n",
    "correlation = analytics.vectorVectorDouble(2)\n",
    "correlation[0] = analytics.vectorDouble([1,0.6])\n",
    "correlation[1] = analytics.vectorDouble([0.6,1])\n",
    "pricing_data.setCorrelations(correlation)\n",
    "pricing_data.pricingRequest = analytics.PricingRequest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.registerSerialization('dummy')\n",
    "tic = datetime.datetime.now()\n",
    "#for i in range(1000000):\n",
    "#pricing_data.save('WOF.json',pricing_data)\n",
    "pr = analytics.price(pricing_data)\n",
    "print('runtime: {}'.format(datetime.datetime.now() - tic))\n",
    "#plot the price\n",
    "pr.getPrice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing with Local Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_high = analytics.vectorVectorDouble(2)\n",
    "correlation_high[0] = analytics.vectorDouble([1,0.99])\n",
    "correlation_high[1] = analytics.vectorDouble([0.99,1])\n",
    "moneyness = analytics.vectorDouble(pl.frange(0.5,1.5,0.005))\n",
    "moneyness_scale = analytics.vectorDouble([100, 100])\n",
    "local_correlation_model = analytics.CorrelationModelLocalPairwise(correlation, correlation_high, moneyness_scale, moneyness)\n",
    "\n",
    "def local_correlation_function(moneyness, t):\n",
    "    result = analytics.vectorVectorDouble(len(moneyness))\n",
    "    kappa = 100\n",
    "    for i in range(len(moneyness)):\n",
    "        tmp = analytics.vectorDouble(len(moneyness))\n",
    "        for j in range(len(moneyness)):\n",
    "            tmp[j] = 1.0 - np.exp(-kappa*(moneyness[i]-moneyness[j])*(moneyness[i]-moneyness[j]))\n",
    "        result[i] = tmp\n",
    "    return result\n",
    "\n",
    "local_corr_function = local_correlation_function(moneyness, 1.0)\n",
    "#local_corr_function = local_correlation_function(moneyness, 3.0)\n",
    "local_correlation_model.addLocalCorrelationFunction(0.1, local_corr_function)\n",
    "pricing_data.correlationModel = local_correlation_model\n",
    "tic = datetime.datetime.now()\n",
    "analytics.registerSerialization('depp')\n",
    "#pricing_data.save('WOF_local_corr.json',pricing_data)\n",
    "pr = analytics.price(pricing_data)\n",
    "print('runtime: {}'.format(datetime.datetime.now() - tic))\n",
    "print(pr.getPrice())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cashflow-Exposure\n",
    "For XVA calculations the future exposures are needed. These exposures at a given time are typically computed from all simulated future cashflows. The MC pricer provides functionality to compute these future cashflows. One has simply to set the times at which the future cashflows are needed into the PricingRequest object. The PricingResults will then contain the PV of the cashflows woch occured between the defined cashflow periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebate = 10\n",
    "pricing_data.spec = ins_tools.create_wof_dop(refdate, [(100.0/spot1, 'DBK'), (100.0/spot2,'EON')], 365, 80, 120, rebate)\n",
    "pricing_data.pricingRequest.setCashflowTimes(converter.createPTimeList(refdate, range(30,366, 30)))\n",
    "#pricing_data.save('WOF_local_corr.json',pricing_data)\n",
    "pr = analytics.price(pricing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pr.getCashflowSlices().cashflowSlices.size())\n",
    "future_cash = pricing_tools.cashflow_profile(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_exposure = []\n",
    "quantile_exposure = []\n",
    "for x in future_cash:\n",
    "    mean_exposure.append(np.mean(x))\n",
    "    quantile_exposure.append(np.percentile(x,60))\n",
    "#n, bins, patches = plt.hist(future_cash[3], 50, normed=1, facecolor='blue', alpha=0.75)\n",
    "plt.plot(mean_exposure,'-x')\n",
    "plt.plot(quantile_exposure,'-^')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricing with stochastic volatility\n",
    "### Setting up PricingData\n",
    "#### Market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochvol_pricing_data = analytics.StochasticVolMonteCarloPricingData()\n",
    "stochvol_pricing_data.valDate = refdate\n",
    "stochvol_pricing_data.spec = spec\n",
    "stochvol_pricing_data.dsc = mkt_testdata.InterestRate.get_curve('EONIA', refdate)\n",
    "stochvol_pricing_data.param = analytics.MonteCarloPricingParameter()\n",
    "stochvol_pricing_data.param.mcParam.numberOfSimulations = 10000\n",
    "stochvol_pricing_data.vols = analytics.vectorConstVolatilities(2)\n",
    "stochvol_pricing_data.vols[0] = env_test.mktman.getVolatilitySurface('DBK') #volatilities are just needed to get current forward curve for Buehle model\n",
    "stochvol_pricing_data.vols[1] = env_test.mktman.getVolatilitySurface('EON')\n",
    "\n",
    "asset_correlations = np.array([ [ 1.0, 0.8 ],\n",
    "                                 [ 0.8, 1.0] ])\n",
    "stochvol_pricing_data.setCorrelations(converter.from_np_matrix(asset_correlations))\n",
    "stochvol_pricing_data.pricingRequest = analytics.PricingRequest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Heston model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0 = 1.0 # we model te Buehler X-Process, therefore we start at 1.0\n",
    "kappa = 1.0\n",
    "theta = 0.04\n",
    "alpha = 0.010\n",
    "v0 = 0.03\n",
    "rho = -0.8\n",
    "pricing_models = [ analytics.HestonModel('HESTON_DAX', refdate, S0, v0, theta, kappa, alpha, rho), analytics.HestonModel('HESTON_STOXX50E', refdate, S0, v0, theta, kappa, alpha, rho)]\n",
    "stochvol_pricing_data.models = analytics.vectorConstModel(pricing_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = datetime.datetime.now()\n",
    "analytics.setLogLevel('DEBUG')\n",
    "#stochvol_pricing_data.save('WOF_stoch_vol.json',stochvol_pricing_data)\n",
    "pr = analytics.price(stochvol_pricing_data)\n",
    "print('runtime: {}'.format(datetime.datetime.now() - tic))\n",
    "#plot the price\n",
    "pr.getPrice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection of model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvacon.pricing.tools as pricing_tools\n",
    "model_param = 'speed of meanreversion'\n",
    "heston_proj = analytics.HestonModel('HESTON_DAX', refdate, S0, v0, theta, kappa, alpha, rho)\n",
    "stochvol_pricing_data.models[0] = heston_proj\n",
    "prices, x, index = pricing_tools.project_model_param(stochvol_pricing_data, heston_proj, model_param, 0.0,2.5,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,prices,'-x')\n",
    "plt.xlabel(model_param)\n",
    "plt.ylabel('price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, s_v_corr, v_v_corr = model_tools.compute_stoch_vol_correlations(pricing_models, [4,4], asset_correlations, 0.0, 0.0)\n",
    "stochvol_pricing_data.setSpotVarianceCorrelations(converter.from_np_matrix(s_v_corr))\n",
    "stochvol_pricing_data.setVarianceVarianceCorrelations(converter.from_np_matrix(v_v_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = datetime.datetime.now()\n",
    "analytics.setLogLevel('DEBUG')\n",
    "pr = analytics.price(stochvol_pricing_data)\n",
    "print('runtime: {}'.format(datetime.datetime.now() - tic))\n",
    "#plot the price\n",
    "pr.getPrice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "464px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
